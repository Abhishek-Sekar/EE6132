{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import flatten #flattening before fc layer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision.datasets import MNIST  #importing MNIST dataset\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms #for transforming the training and testing data \n",
    "from torch.utils.data import DataLoader #Dataloader loads the data batchwise with shuffling in a hassle free manner\n",
    "from torch.optim import Adam #Adam for GD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler #performs normalization\n",
    "from mnist import MNIST as MNIST1 #a python package which has the mnist loaders\n",
    "from sklearn.metrics import mean_squared_error as mse #for MSE \n",
    "from PIL import Image as im #used to convert the given image array to a b/w image\n",
    "from skimage import img_as_ubyte #preserving 0-255 range for skimage.transform.resize\n",
    "import skimage.transform #to resize the image\n",
    "from torchvision.utils import make_grid #to visualize the kernels the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags for running various parts of the assignment\n",
    "\n",
    "download_flag = False\n",
    "load_model    = False\n",
    "master_dir = os.getcwd() #this is the directory we're working in\n",
    "mnist_dir     = 'mnist_A2' #directory to store the MNIST dataset\n",
    "mnist_dir_PCA = \"mnist\"\n",
    "mnist_path = os.path.join(master_dir,mnist_dir_PCA) #change name to path where mnist is downloaded to\n",
    "model_dir     = 'AE_model' #directory containing the AE model\n",
    "download_dir  = 'C:\\\\Users\\\\ABHISHEK\\\\Downloads\\\\EE6132Ass3'\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(master_dir, mnist_dir)):\n",
    "        os.mkdir(os.path.join(master_dir, mnist_dir)) #make the directory if it doesn't exist\n",
    "\n",
    "if not os.path.exists(os.path.join(master_dir, model_dir)):\n",
    "        os.mkdir(os.path.join(master_dir, model_dir)) #make the directory if it doesn't exist\n",
    "model_path = os.path.join(master_dir, model_dir)+'/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize_Image(test_images):\n",
    "    \n",
    "    data_ind  = [6003,416,6754,1605,5055,7965,517,5551,7070,6420] #indices of various digits from the test set\n",
    "    \n",
    "    for i,ind in enumerate(data_ind):\n",
    "        \n",
    "        #visualizing the image just for clarity\n",
    "        image_sample = np.asarray(test_images[ind],dtype = np.uint8).reshape(28,28)\n",
    "\n",
    "        #creating image object\n",
    "        image_obj = im.fromarray(image_sample) #converts the array into a b/w image 28x28\n",
    "\n",
    "        #saving the image\n",
    "        image_obj.save(download_dir+'\\\\'+str(i) +'.png')\n",
    "        print('Digit '+str(i)+' image has been saved')\n",
    "        image_obj.show()\n",
    "        \n",
    "\n",
    "def Visualize_Reconstr_PCA(reconstructed_data):\n",
    "    \n",
    "    data_ind  = [6003,416,6754,1605,5055,7965,517,5551,7070,6420] #indices of various digits from the test set\n",
    "    \n",
    "    for i,ind in enumerate(data_ind):\n",
    "        \n",
    "        #visualizing the image just for clarity\n",
    "        image_sample = np.asarray(255*reconstructed_data[ind],dtype = np.uint8).reshape(28,28)\n",
    "\n",
    "        #creating image object\n",
    "        image_obj = im.fromarray(image_sample) #converts the array into a b/w image 28x28\n",
    "\n",
    "        #saving the image\n",
    "        image_obj.save(download_dir+'\\\\'+str(i) +' PCA reconstructed.png')\n",
    "        print('Digit '+str(i)+' image has been saved')\n",
    "        image_obj.show()\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a class with the required AE architecture\n",
    "\n",
    "class AE(nn.Module):\n",
    "    \n",
    "    def __init__(self): #class constructor\n",
    "        super(AE,self).__init__() #calls the parent constructor\n",
    "        \n",
    "        #initializing the encoder module\n",
    "        self.encoder = nn.Sequential(nn.Linear(784,512),nn.ReLU(),nn.Linear(512,256),nn.ReLU(),nn.Linear(256,128),nn.ReLU(),nn.Linear(128,30))\n",
    "        \n",
    "        #initializing the decoder module\n",
    "        self.decoder = nn.Sequential(nn.Linear(30,128),nn.ReLU(),nn.Linear(128,256),nn.ReLU(),nn.Linear(256,784),nn.ReLU())\n",
    "        \n",
    "    def forward(self,x): #defines the forward pass and also the structure of the network thus helping backprop\n",
    "        \n",
    "        x                   = flatten(x,1) #flatten the image to a 784x1 vector\n",
    "        encoded_input       = self.encoder(x.float())\n",
    "        reconstructed_input = self.decoder(encoded_input)\n",
    "        \n",
    "        return reconstructed_input,encoded_input\n",
    "    \n",
    "\n",
    "class AE_1h(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_layer): #class constructor\n",
    "        super(AE_1h,self).__init__() #calls the parent constructor\n",
    "        \n",
    "        #initializing the encoder module\n",
    "        self.encoder = nn.Sequential(nn.Linear(784,hidden_layer),nn.ReLU())\n",
    "        \n",
    "        #initializing the decoder module\n",
    "        self.decoder = nn.Sequential(nn.Linear(hidden_layer,784),nn.ReLU())\n",
    "        \n",
    "    def forward(self,x): #defines the forward pass and also the structure of the network thus helping backprop\n",
    "        \n",
    "        x                   = flatten(x,1) #flatten the image to a 784x1 vector\n",
    "        encoded_input       = self.encoder(x.float())\n",
    "        reconstructed_input = self.decoder(encoded_input)\n",
    "        \n",
    "        return reconstructed_input,encoded_input\n",
    "    \n",
    "\n",
    "class AE_manifold(nn.Module):\n",
    "    \n",
    "    def __init__(self): #class constructor\n",
    "        super(AE_manifold,self).__init__() #calls the parent constructor\n",
    "        \n",
    "        #initializing the encoder module\n",
    "        self.encoder = nn.Sequential(nn.Linear(784,64),nn.ReLU(),nn.Linear(64,8),nn.ReLU())\n",
    "        \n",
    "        #initializing the decoder module\n",
    "        self.decoder = nn.Sequential(nn.Linear(8,64),nn.ReLU(),nn.Linear(64,784),nn.ReLU())\n",
    "        \n",
    "    def forward(self,x): #defines the forward pass and also the structure of the network thus helping backprop\n",
    "        \n",
    "        x                   = flatten(x,1) #flatten the image to a 784x1 vector\n",
    "        encoded_input       = self.encoder(x.float())\n",
    "        reconstructed_input = self.decoder(encoded_input)\n",
    "        \n",
    "        return reconstructed_input,encoded_input\n",
    "        \n",
    "class conv_AE_unpool(nn.Module): #define unpooling outside the decoder and separately in forward nn.Sequential just takes one input\n",
    "    \n",
    "    def __init__(self): #class constructor\n",
    "        super(conv_AE_unpool,self).__init__() #calls the parent constructor\n",
    "        \n",
    "        #initializing the encoder module\n",
    "        self.encoder_conv1 = nn.Sequential(nn.Conv2d(1,8, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2),return_indices = True)) # 28x28x1 to 14x14x8\n",
    "        self.encoder_conv2 = nn.Sequential(nn.Conv2d(8,16, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2),return_indices = True)) #14x14x8 to 7x7x16\n",
    "        self.encoder_conv3 = nn.Sequential(nn.Conv2d(16,16, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2),return_indices = True)) #7x7x16 to 3x3x16\n",
    "        \n",
    "        #initializing the decoder module\n",
    "        self.decoder_conv1 = nn.Sequential(nn.Identity()) #7x7x16 to 7x7x16\n",
    "        self.decoder_conv2 = nn.Sequential(nn.Conv2d(16,8, kernel_size = 3, stride = 1,padding= 1),nn.ReLU()) #14x14x16 to 14x14x8\n",
    "        self.decoder_conv3 = nn.Sequential(nn.Conv2d(8,1, kernel_size = 3, stride = 1,padding= 1),nn.ReLU()) #28x28x8 to 28x28x1\n",
    "        \n",
    "        #defining the unpooling operation\n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size = (2,2))\n",
    "        \n",
    "        \n",
    "    def forward(self,x): #defines the forward pass and also the structure of the network thus helping backprop\n",
    "        \n",
    "        encoded_input,indices1  = self.encoder_conv1(x.float())  # 28x28x1 to 14x14x8\n",
    "        encoded_input,indices2  = self.encoder_conv2(encoded_input) #14x14x8 to 7x7x16\n",
    "        encoded_input,indices3  = self.encoder_conv3(encoded_input) #7x7x16 to 3x3x16\n",
    "        \n",
    "        \n",
    "        reconstructed_input     = self.unpool(encoded_input,indices3,output_size=torch.Size([batch_size, 16, 7, 7])) #3x3x16 to 7x7x16\n",
    "        reconstructed_input     = self.decoder_conv1(reconstructed_input) #7x7x16 to 7x7x16\n",
    "        reconstructed_input     = self.unpool(reconstructed_input,indices2) #7x7x16 to 14x14x16\n",
    "        reconstructed_input     = self.decoder_conv2(reconstructed_input)#14x14x16 to 14x14x8\n",
    "        reconstructed_input     = self.unpool(reconstructed_input,indices1)#14x14x8 to 28x28x8\n",
    "        reconstructed_input     = self.decoder_conv3(reconstructed_input)#28x28x8 to 28x28x1\n",
    "\n",
    "        \n",
    "        return reconstructed_input,encoded_input\n",
    "    \n",
    "class conv_AE_deconv(nn.Module):\n",
    "    def __init__(self): #class constructor\n",
    "        super(conv_AE_deconv,self).__init__() #calls the parent constructor\n",
    "        \n",
    "        #initializing the encoder module\n",
    "        self.encoder_conv1 = nn.Sequential(nn.Conv2d(1,8, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2)))\n",
    "        self.encoder_conv2 = nn.Sequential(nn.Conv2d(8,16, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2)))\n",
    "        self.encoder_conv3 = nn.Sequential(nn.Conv2d(16,16, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2)))\n",
    "        \n",
    "        #initializing the decoder module\n",
    "        self.decoder_conv1 = nn.Sequential(nn.ConvTranspose2d(16,16, kernel_size = 3, stride = 2),nn.ReLU())\n",
    "        self.decoder_conv2 = nn.Sequential(nn.ConvTranspose2d(16,8, kernel_size = 4, stride = 2, padding = 1),nn.ReLU())\n",
    "        self.decoder_conv3 = nn.Sequential(nn.ConvTranspose2d(8,1, kernel_size = 4, stride = 2, padding = 1),nn.ReLU())\n",
    "        \n",
    "    def forward(self,x): #defines the forward pass and also the structure of the network thus helping backprop\n",
    "        \n",
    "        encoded_input  = self.encoder_conv1(x.float())\n",
    "        encoded_input  = self.encoder_conv2(encoded_input)\n",
    "        encoded_input  = self.encoder_conv3(encoded_input)\n",
    "\n",
    "        reconstructed_input     = self.decoder_conv1(encoded_input)\n",
    "        reconstructed_input     = self.decoder_conv2(reconstructed_input)\n",
    "        reconstructed_input     = self.decoder_conv3(reconstructed_input)\n",
    "\n",
    "        return reconstructed_input,encoded_input\n",
    "\n",
    "class conv_AE_deconv_unpool(nn.Module):\n",
    "    def __init__(self): #class constructor\n",
    "        super(conv_AE_deconv_unpool,self).__init__() #calls the parent constructor\n",
    "        \n",
    "         #initializing the encoder module\n",
    "        self.encoder_conv1 = nn.Sequential(nn.Conv2d(1,8, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2),return_indices = True))\n",
    "        self.encoder_conv2 = nn.Sequential(nn.Conv2d(8,16, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2),return_indices = True))\n",
    "        self.encoder_conv3 = nn.Sequential(nn.Conv2d(16,16, kernel_size = 3, stride = 1,padding= 1),nn.ReLU(),nn.MaxPool2d(kernel_size = (2,2),return_indices = True))\n",
    "        \n",
    "        #initializing the decoder module\n",
    "        self.decoder_conv1 = nn.Sequential(nn.ConvTranspose2d(16,16, kernel_size = 3, stride = 1, padding = 1),nn.ReLU())\n",
    "        self.decoder_conv2 = nn.Sequential(nn.ConvTranspose2d(16,8, kernel_size = 3, stride = 1, padding = 1),nn.ReLU())\n",
    "        self.decoder_conv3 = nn.Sequential(nn.ConvTranspose2d(8,1, kernel_size = 3, stride = 1, padding = 1),nn.ReLU())\n",
    "        \n",
    "        #defining the unpooling operation\n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size = (2,2))\n",
    "        \n",
    "    def forward(self,x): #defines the forward pass and also the structure of the network thus helping backprop\n",
    "        \n",
    "        encoded_input,indices1  = self.encoder_conv1(x.float())\n",
    "        encoded_input,indices2  = self.encoder_conv2(encoded_input)\n",
    "        encoded_input,indices3  = self.encoder_conv3(encoded_input)\n",
    "        \n",
    "        \n",
    "        reconstructed_input     = self.unpool(encoded_input,indices3,output_size=torch.Size([batch_size, 16, 7, 7]))\n",
    "        reconstructed_input     = self.decoder_conv1(reconstructed_input)\n",
    "        reconstructed_input     = self.unpool(reconstructed_input,indices2)\n",
    "        reconstructed_input     = self.decoder_conv2(reconstructed_input)\n",
    "        reconstructed_input     = self.unpool(reconstructed_input,indices1)\n",
    "        reconstructed_input     = self.decoder_conv3(reconstructed_input)\n",
    "        \n",
    "        \n",
    "        return reconstructed_input,encoded_input        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to train the network: Returns the training loss for the current epoch \n",
    "def Train(model,device,TrainDataLoader,optimizer,lossfn,train_length,sparse = False,l1_reg = 0.001,denoise = False,noise_val=0.1,model_flag = 0):  \n",
    "    \n",
    "    model.train() #setting the model in training mode\n",
    "    \n",
    "    #initializing the total training loss to 0\n",
    "    train_loss    = 0\n",
    "     \n",
    "    #loop over the training set\n",
    "    \n",
    "    for (data,label) in tqdm(TrainDataLoader):  # (data,label): Training data for that batch\n",
    "        \n",
    "        (data,label) = (data.to(device),label.to(device))  #sending the data to the device we've chosen\n",
    "        \n",
    "        if((denoise == False)and (model_flag < 3)):\n",
    "            #perform forward pass and compute the loss\n",
    "        \n",
    "            reconstruction,encoded = model(data) #our reconstruction\n",
    "            loss = lossfn(reconstruction,flatten(data,1)) #loss \n",
    "        \n",
    "            if(sparse == True):\n",
    "                loss += l1_reg*torch.linalg.norm(encoded,1) #imposing L1 penalty on the hidden layer activation for sparse AE\n",
    "            \n",
    "            optimizer.zero_grad() #zeroing out the gradients before backprop\n",
    "            loss.backward()       #backprop from the loss\n",
    "            optimizer.step()      #updating the weights\n",
    "        \n",
    "        elif(denoise == True):\n",
    "            noisy_data = Add_Noise(data, noise_val)\n",
    "            \n",
    "            #perform forward pass and compute the loss\n",
    "        \n",
    "            reconstruction,encoded = model(noisy_data) #our reconstruction\n",
    "            loss = lossfn(reconstruction,flatten(data,1)) #loss wrt original data\n",
    "            \n",
    "            optimizer.zero_grad() #zeroing out the gradients before backprop\n",
    "            loss.backward()       #backprop from the loss\n",
    "            optimizer.step()      #updating the weights\n",
    "        \n",
    "        elif(model_flag >= 3):\n",
    "            \n",
    "            #perform forward pass and compute the loss\n",
    "            reconstruction,encoded = model(data) #our reconstruction\n",
    "            loss = lossfn(reconstruction,data) #loss\n",
    "            \n",
    "            optimizer.zero_grad() #zeroing out the gradients before backprop\n",
    "            loss.backward()       #backprop from the loss\n",
    "            optimizer.step()      #updating the weights\n",
    "            \n",
    "            \n",
    "        \n",
    "        #Adding this loss to  training loss and computing correct predictions\n",
    "        \n",
    "        train_loss    += loss/train_length\n",
    "    \n",
    "    return train_loss #returning loss\n",
    "\n",
    "\n",
    "#Defining a function to test the network: Returns the test loss for the current epoch\n",
    "def Test(model,device,TestDataLoader,lossfn,test_length,sparse = False,l1_reg = 0.001,denoise = False,noise_val=0.1,model_flag = 0):\n",
    "    \n",
    "    model.eval()  #setting the model in eval/test mode\n",
    "    \n",
    "    #initializing the total test loss and total correct test predictions to 0\n",
    "    test_loss    = 0\n",
    "    \n",
    "    #switching off the gradient for eval\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #loop over the test set\n",
    "        \n",
    "        for (data,label) in TestDataLoader: # (data,label): Test data for that batch\n",
    "            \n",
    "            (data,label) = (data.to(device),label.to(device))  #sending the data to the device we've chosen\n",
    "        \n",
    "            \n",
    "            if((denoise == False)and (model_flag < 3)):\n",
    "                #perform forward pass and compute the loss\n",
    "                reconstruction,encoded = model(data) #our prediction\n",
    "                loss = lossfn(reconstruction,flatten(data,1)) #loss \n",
    "            \n",
    "                if(sparse == True):\n",
    "                    \n",
    "                    loss += l1_reg*torch.linalg.norm(encoded,1) #imposing L1 penalty on the hidden layer activation for sparse AE\n",
    "            \n",
    "            elif(denoise == True):\n",
    "                noisy_data = Add_Noise(data, noise_val)\n",
    "            \n",
    "                #perform forward pass and compute the loss\n",
    "        \n",
    "                reconstruction,encoded = model(noisy_data) #our reconstruction\n",
    "                loss = lossfn(reconstruction,flatten(data,1)) #loss wrt original data\n",
    "            \n",
    "            elif(model_flag >= 3):\n",
    "            \n",
    "                #perform forward pass and compute the loss\n",
    "        \n",
    "                reconstruction,encoded = model(data) #our reconstruction\n",
    "                loss = lossfn(reconstruction,data) #loss\n",
    "            \n",
    "                \n",
    "            #Adding this loss to  test loss\n",
    "        \n",
    "            test_loss    += loss/test_length\n",
    "    \n",
    "    return test_loss #returning loss\n",
    "def average_act(model,device,TestDataLoader,lossfn,test_length):\n",
    "    model.eval()  #setting the model in eval/test mode\n",
    "    \n",
    "    #initializing the total test loss and total correct test predictions to 0\n",
    "    average_act_val    = 0\n",
    "    \n",
    "    #switching off the gradient for eval\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #loop over the test set\n",
    "        \n",
    "        for (data,label) in TestDataLoader: # (data,label): Test data for that batch\n",
    "            \n",
    "            (data,label) = (data.to(device),label.to(device))  #sending the data to the device we've chosen\n",
    "        \n",
    "            \n",
    "        \n",
    "            #perform forward pass and compute the average activation\n",
    "            reconstruction,encoded = model(data) #our prediction \n",
    "                    \n",
    "            average_act_val += float(torch.mean(encoded))        \n",
    "                \n",
    "        \n",
    "        \n",
    "    average_act_val    /= test_length\n",
    "    \n",
    "    print('The average activation norm is ',average_act_val)\n",
    "            \n",
    "        \n",
    "    \n",
    "def Test_Image(model,model_name,device,img,name):\n",
    "    \n",
    "    img = torch.from_numpy(img)\n",
    "    \n",
    "    print('Loading Model')\n",
    "        \n",
    "    model.load_state_dict(torch.load(model_path+model_name), strict=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if(device == torch.device(\"cuda\")): #if we're working on a GPU\n",
    "            test_image = img.reshape(1,1,28,28).cuda().float() #reshaping the image into 28x28 pixels\n",
    "\n",
    "        else:\n",
    "            test_image = img.reshape(1,1,28,28).float()\n",
    "                    \n",
    "            \n",
    "        #detach breaks the image from the computational graph layer of the tensor before converting it to numpy format\n",
    "\n",
    "        reconstructed_image,encoded = model.forward(test_image) #as it is a single image we directly run the forward pass\n",
    "                \n",
    "        plt.imshow(reconstructed_image.reshape(28,28),cmap = plt.cm.gray, interpolation='nearest',clim=(0, 255)) #our reconstructed image\n",
    "        str_title = \"Reconstructed image: \"+name\n",
    "        plt.title(str_title)\n",
    "        plt.savefig(download_dir+'\\\\'+'Reconstructed_Image_'+name+model_name+'.png')\n",
    "        plt.show()\n",
    "    \n",
    "def Visualize_activations(model,TestDataLoader,model_name,device,hidden_layer): #visualize the activations\n",
    "    data_ind  = [6003,416,6754,1605,5055,7965,517,5551,7070,6420] #indices of various digits from the test set\n",
    "    \n",
    "    print('Loading Model')\n",
    "        \n",
    "    model.load_state_dict(torch.load(model_path+model_name), strict=False)\n",
    "    \n",
    "    for i,ind in enumerate(data_ind):\n",
    "            \n",
    "        test_image = TestDataLoader.dataset.data[ind].clone()  #creates a copy of the test_image from the dataset\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            if(device == torch.device(\"cuda\")): #if we're working on a GPU\n",
    "                test_image = test_image.reshape(1,1,28,28).cuda().float() #reshaping the image into 28x28 pixels\n",
    "\n",
    "            else:\n",
    "                test_image = test_image.reshape(1,1,28,28).float()\n",
    "                    \n",
    "            \n",
    "            #detach breaks the image from the computational graph layer of the tensor before converting it to numpy format\n",
    "\n",
    "            reconstructed_image,encoded = model.forward(test_image) #as it is a single image we directly run the forward pass\n",
    "                    \n",
    "            encoded = encoded.detach().cpu().numpy()\n",
    "            plt.imshow(encoded.reshape(int(np.sqrt(hidden_layer)),int(np.sqrt(hidden_layer)))) #our activation image assuming hidden layer size is 900\n",
    "            str_title = \"Activation for digit \"+str(i)\n",
    "            plt.title(str_title)\n",
    "            plt.savefig(download_dir+'\\\\'+'Activation_Image_'+str(i)+model_name+'.png')\n",
    "            plt.show()\n",
    "\n",
    "def Visualize_Filters(model,model_name,device): #visualize the weights for ten neurons spaced\n",
    "    \n",
    "    print('Loading Model')\n",
    "        \n",
    "    model.load_state_dict(torch.load(model_path+model_name), strict=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        encoder_filters = model.encoder[0].weight.detach().cpu().numpy()\n",
    "        decoder_filters = model.decoder[0].weight.detach().cpu().numpy()\n",
    "        \n",
    "        #plot the encoder and decoder weights as an image\n",
    "        \n",
    "        for i in range(10):\n",
    "        \n",
    "            plt.imshow(encoder_filters[10*i].reshape(28,28))\n",
    "            plt.colorbar()\n",
    "            plt.title('Encoder Filters for '+str(10*i)+'th neuron')\n",
    "            plt.savefig(download_dir+'\\\\'+'Encoder_filters'+str(10*i)+model_name+'.png')\n",
    "            plt.show()\n",
    "        \n",
    "            plt.imshow(decoder_filters[:,10*i].reshape(28,28))\n",
    "            plt.colorbar()\n",
    "            plt.title('Decoder Filters for '+str(10*i)+'th neuron')\n",
    "            plt.savefig(download_dir+'\\\\'+'Decoder_filters'+str(10*i)+model_name+'.png')\n",
    "            plt.show()\n",
    "    \n",
    "def Add_Noise(image, noise_val = 0.3 ): #adding salt and pepper noise \n",
    "\n",
    "    noise = torch.randn(image.size())*noise_val\n",
    "    noisy_image = image + noise\n",
    "    return noisy_image\n",
    "\n",
    "def Manifold_Analysis(model,TestDataLoader,model_name,device,noise_val):\n",
    "    data_ind  = [6003,416,6754,1605,5055,7965,517,5551,7070,6420] #indices of various digits from the test set\n",
    "    \n",
    "    print('Loading Model')\n",
    "        \n",
    "    model.load_state_dict(torch.load(model_path+model_name), strict=False)\n",
    "    \n",
    "    for i,ind in enumerate(data_ind):\n",
    "            \n",
    "        test_image = TestDataLoader.dataset.data[ind].clone()  #creates a copy of the test_image from the dataset\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            if(device == torch.device(\"cuda\")): #if we're working on a GPU\n",
    "                test_image = test_image.reshape(1,1,28,28).cuda().float() #reshaping the image into 28x28 pixels\n",
    "\n",
    "            else:\n",
    "                test_image = test_image.reshape(1,1,28,28).float()\n",
    "                    \n",
    "            \n",
    "            encoded = model.encoder[3].forward(test_image) #obtaining the encoded output\n",
    "            encoded = Add_Noise(encoded,noise_val) #adding noise to the feature before passing it onto the decoder\n",
    "            reconstructed_image = model.decoder[3].forward(encoded)\n",
    "            \n",
    "            reconstructed_image = reconstructed_image.detach().cpu().numpy()\n",
    "            plt.imshow(reconstructed_image.reshape(28,28),cmap = plt.cm.gray, interpolation='nearest',clim=(0, 255)) #our reconstructed image\n",
    "            str_title = \"Reconstructed image: \"+str(i)\n",
    "            plt.title(str_title)\n",
    "            plt.savefig(download_dir+'\\\\'+'Reconstructed_Image_Manifold'+str(i)+str(noise_val)+model_name+'.png')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "def Visualize_Decoder_Weights(model,model_name,device,model_flag):\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path+model_name), strict=False) #loading the model\n",
    "    \n",
    "    if(model_flag == 3): #CAE with just unpooling\n",
    "            \n",
    "        conv_2_filter = model.decoder_conv2[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_2_filter = conv_2_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_2_filter -= conv_2_filter.min()\n",
    "        conv_2_filter /= conv_2_filter.max()\n",
    "        \n",
    "        #all the filters are block filters\n",
    "        #Therefore, using a random number generator to choose which block filters to plot\n",
    "        filt_ind = np.random.randint(0 ,conv_2_filter.size()[0],3)\n",
    "        \n",
    "        for ind in filt_ind:  \n",
    "            print(conv_2_filter[ind].size())\n",
    "\n",
    "            image         = make_grid(conv_2_filter[ind].reshape(16,1,3,3)) #this returns a tensor grid containing the images\n",
    "            print(image.size())\n",
    "            image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "            #plotting the second layer filters\n",
    "            plt.imshow(image)\n",
    "            str_title = 'Decoder Second Convolutional Layer Filter no: ' + str(ind)\n",
    "            plt.title(str_title)\n",
    "            plt.savefig(download_dir+'\\\\'+'DecoderConv2'+str(ind)+model_name+'.png')\n",
    "            plt.show()\n",
    "        \n",
    "        conv_3_filter = model.decoder_conv3[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_3_filter = conv_3_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_3_filter -= conv_3_filter.min()\n",
    "        conv_3_filter /= conv_3_filter.max()\n",
    "        print(conv_3_filter.size())\n",
    "        image         = make_grid(conv_3_filter.reshape(8,1,3,3)) #this returns a tensor grid containing the images\n",
    "        image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "        #plotting the second layer filters\n",
    "        plt.imshow(image)\n",
    "        str_title = 'Decoder Third Convolutional Layer Filter'\n",
    "        plt.title(str_title)\n",
    "        plt.savefig(download_dir+'\\\\'+'DecoderConv3'+str(ind)+model_name+'.png')\n",
    "        plt.show()    \n",
    "        \n",
    "    \n",
    "    elif(model_flag == 4): #CAE with just deconvolution\n",
    "        print(model)\n",
    "        conv_1_filter = model.decoder_conv1[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_1_filter = conv_1_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_1_filter -= conv_1_filter.min()\n",
    "        conv_1_filter /= conv_1_filter.max()\n",
    "        \n",
    "        #all the filters are block filters\n",
    "        #Therefore, using a random number generator to choose which block filters to plot\n",
    "        filt_ind = np.random.randint(0 ,conv_1_filter.size()[0],3)\n",
    "        \n",
    "        for ind in filt_ind:    \n",
    "\n",
    "            image         = make_grid(conv_1_filter[ind].reshape(16,1,3,3)) #this returns a tensor grid containing the images\n",
    "            image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "            #plotting the second layer filters\n",
    "            plt.imshow(image)\n",
    "            str_title = 'Decoder First Convolutional Layer Filter no: ' + str(ind)\n",
    "            plt.title(str_title)\n",
    "            plt.savefig(download_dir+'\\\\'+'DecoderConv1'+str(ind)+model_name+'.png')\n",
    "            plt.show()\n",
    "            \n",
    "        conv_2_filter = model.decoder_conv2[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_2_filter = conv_2_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_2_filter -= conv_2_filter.min()\n",
    "        conv_2_filter /= conv_2_filter.max()\n",
    "        \n",
    "        #all the filters are block filters\n",
    "        #Therefore, using a random number generator to choose which block filters to plot\n",
    "        filt_ind = np.random.randint(0 ,conv_2_filter.size()[0],3)\n",
    "        \n",
    "        for ind in filt_ind:   \n",
    "            print(conv_2_filter[ind].size())\n",
    "\n",
    "            image         = make_grid(conv_2_filter[ind].reshape(8,1,4,4)) #this returns a tensor grid containing the images\n",
    "            image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "            #plotting the second layer filters\n",
    "            plt.imshow(image)\n",
    "            str_title = 'Decoder Second Convolutional Layer Filter no: ' + str(ind)\n",
    "            plt.title(str_title)\n",
    "            plt.savefig(download_dir+'\\\\'+'DecoderConv2'+str(ind)+model_name+'.png')\n",
    "            plt.show()\n",
    "        \n",
    "        conv_3_filter = model.decoder_conv3[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_3_filter = conv_3_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_3_filter -= conv_3_filter.min()\n",
    "        conv_3_filter /= conv_3_filter.max()\n",
    "        print(conv_3_filter.size())\n",
    "        \n",
    "        image         = make_grid(conv_3_filter.reshape(8,1,4,4)) #this returns a tensor grid containing the images\n",
    "        image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "        #plotting the second layer filters\n",
    "        plt.imshow(image)\n",
    "        str_title = 'Decoder Third Convolutional Layer Filter'\n",
    "        plt.title(str_title)\n",
    "        plt.savefig(download_dir+'\\\\'+'DecoderConv3'+str(ind)+model_name+'.png')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    elif(model_flag == 5): #CAE with both deconvolution and unpooling\n",
    "        conv_1_filter = model.decoder_conv1[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_1_filter = conv_1_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_1_filter -= conv_1_filter.min()\n",
    "        conv_1_filter /= conv_1_filter.max()\n",
    "        \n",
    "        #all the filters are block filters\n",
    "        #Therefore, using a random number generator to choose which block filters to plot\n",
    "        filt_ind = np.random.randint(0 ,conv_1_filter.size()[0],3)\n",
    "        \n",
    "        for ind in filt_ind:    \n",
    "\n",
    "            image         = make_grid(conv_1_filter[ind].reshape(16,1,3,3)) #this returns a tensor grid containing the images\n",
    "            image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "            #plotting the second layer filters\n",
    "            plt.imshow(image)\n",
    "            str_title = 'Decoder First Convolutional Layer Filter no: ' + str(ind)\n",
    "            plt.title(str_title)\n",
    "            plt.savefig(download_dir+'\\\\'+'DecoderConv1:'+str(ind)+model_name+'.png')\n",
    "            plt.show()\n",
    "            \n",
    "        conv_2_filter = model.decoder_conv2[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_2_filter = conv_2_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_2_filter -= conv_2_filter.min()\n",
    "        conv_2_filter /= conv_2_filter.max()\n",
    "        \n",
    "        #all the filters are block filters\n",
    "        #Therefore, using a random number generator to choose which block filters to plot\n",
    "        filt_ind = np.random.randint(0 ,conv_2_filter.size()[0],3)\n",
    "        \n",
    "        for ind in filt_ind: \n",
    "\n",
    "            image         = make_grid(conv_2_filter[ind].reshape(8,1,3,3)) #this returns a tensor grid containing the images\n",
    "            image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "            #plotting the second layer filters\n",
    "            plt.imshow(image)\n",
    "            str_title = 'Decoder Second Convolutional Layer Filter no: ' + str(ind)\n",
    "            plt.title(str_title)\n",
    "            plt.savefig(download_dir+'\\\\'+'DecoderConv2:'+str(ind)+model_name+'.png')\n",
    "            plt.show()\n",
    "        \n",
    "        conv_3_filter = model.decoder_conv3[0].weight.detach().clone() #creating a copy of the filter weights\n",
    "        \n",
    "        if(device == torch.device('cuda')):\n",
    "            conv_3_filter = conv_3_filter.cpu() #get it to the CPU\n",
    "            \n",
    "        #normalizing the filters by scaling the values this makes it stand out from the background\n",
    "        conv_3_filter -= conv_3_filter.min()\n",
    "        conv_3_filter /= conv_3_filter.max()\n",
    "        \n",
    "        image         = make_grid(conv_3_filter.reshape(8,1,3,3)) #this returns a tensor grid containing the images\n",
    "        image         = image.permute(1,2,0) #permuting the dimensions of the tensor grid to make it right \n",
    "\n",
    "        #plotting the second layer filters\n",
    "        plt.imshow(image)\n",
    "        str_title = 'Decoder Third Convolutional Layer Filter '\n",
    "        plt.title(str_title)\n",
    "        plt.savefig(download_dir+'\\\\'+'DecoderConv3:'+str(ind)+model_name+'.png')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "def Run_AE(model_name,load_model,model_flag,hidden_layer=256,sparse = False,l1_reg = 0.001,pltmode = 0,img = 0,name = '0',denoise = False,noise_val = 0.1):\n",
    "    \n",
    "    app_transform = transforms.ToTensor() #convert the images to tensor datatype\n",
    "    \n",
    "    #organize the training and test data\n",
    "    \n",
    "    train_data    = MNIST(mnist_dir, train = True, download = download_flag, transform = app_transform) #getting training data\n",
    "    test_data     = MNIST(mnist_dir, train = False, transform = app_transform)\n",
    "    \n",
    "    #initialize the dataloaders\n",
    "    TrainDataLoader = DataLoader(train_data, batch_size = batch_size, shuffle = True ) \n",
    "    TestDataLoader  = DataLoader(test_data, batch_size = batch_size) \n",
    "    \n",
    "    train_length  = len(TrainDataLoader.dataset) #no of training examples\n",
    "    test_length   = len(TestDataLoader.dataset)  #no of testing cases\n",
    "    \n",
    "    #model\n",
    "    if(model_flag == 0):\n",
    "        model = AE().to(device)\n",
    "    elif(model_flag == 1):\n",
    "        model = AE_1h(hidden_layer=hidden_layer).to(device)\n",
    "    \n",
    "    elif(model_flag == 2):\n",
    "        model = AE_manifold().to(device)\n",
    "        \n",
    "    elif(model_flag == 3):\n",
    "        model = conv_AE_unpool().to(device)\n",
    "        #model = CNN().to(device)\n",
    "        \n",
    "    elif(model_flag == 4):\n",
    "        model = conv_AE_deconv().to(device)\n",
    "    \n",
    "    elif(model_flag == 5):\n",
    "        model = conv_AE_deconv_unpool().to(device)\n",
    "    \n",
    "    #initialize the optimizer\n",
    "    optimizer = Adam(model.parameters(),lr = learning_rate) #using Adam for GD as its the fastest and state of the art\n",
    "    \n",
    "    #loss function:MSE\n",
    "    lossfn = nn.MSELoss()\n",
    "    \n",
    "    if(load_model): #load a pre-trained model\n",
    "        if(pltmode == 0):\n",
    "            print('Loading Model')\n",
    "        \n",
    "            model.load_state_dict(torch.load(model_path+model_name), strict=False)\n",
    "            \n",
    "        \n",
    "            #viewing the reconstructed images\n",
    "            data_ind  = [6003,416,6754,1605,5055,7965,517,5551,7070,6420] #indices of various digits from the test set\n",
    "        \n",
    "            for i,ind in enumerate(data_ind):\n",
    "            \n",
    "                test_image = TestDataLoader.dataset.data[ind].clone()  #creates a copy of the test_image from the dataset\n",
    "                \n",
    "                if(denoise == True):\n",
    "                    noisy_image = Add_Noise(test_image,noise_val)\n",
    "                    test_image  = noisy_image\n",
    "                    noisy_image = noisy_image.detach().cpu().numpy()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #plot the noisy image\n",
    "                    plt.imshow(noisy_image.reshape(28,28),cmap='gray') #our noisy image\n",
    "                    str_title = \"Noisy image \"+str(i)\n",
    "                    plt.title(str_title)\n",
    "                    plt.savefig(download_dir+'\\\\'+'Noisy_Image_'+str(i)+model_name+'.png')\n",
    "                    plt.show()\n",
    "                    \n",
    "                    \n",
    "            \n",
    "                with torch.no_grad():\n",
    "                    if(device == torch.device(\"cuda\")): #if we're working on a GPU\n",
    "                        test_image = test_image.reshape(1,1,28,28).cuda().float() #reshaping the image into 28x28 pixels\n",
    "\n",
    "                    else:\n",
    "                        test_image = test_image.reshape(1,1,28,28).float()\n",
    "                    \n",
    "            \n",
    "                    #detach breaks the image from the computational graph layer of the tensor before converting it to numpy format\n",
    "\n",
    "                    reconstructed_image,encoded = model.forward(test_image) #as it is a single image we directly run the forward pass\n",
    "                    \n",
    "                    reconstructed_image = reconstructed_image.detach().cpu().numpy()\n",
    "                    plt.imshow(reconstructed_image.reshape(28,28),cmap='gray') #our reconstructed image\n",
    "                    str_title = \"Reconstructed image \"+str(i)\n",
    "                    plt.title(str_title)\n",
    "                    plt.savefig(download_dir+'\\\\'+'Reconstructed_Image_'+str(i)+model_name+'.png')\n",
    "                    plt.show()\n",
    "            \n",
    "    \n",
    "        if(pltmode == 1):\n",
    "            Test_Image(model,model_name,device,img,name)\n",
    "            \n",
    "        if(pltmode == 2):\n",
    "            Visualize_activations(model,TestDataLoader,model_name,device,hidden_layer)\n",
    "            \n",
    "        if(pltmode == 3):\n",
    "            Visualize_Filters(model,model_name,device)\n",
    "            \n",
    "        if(pltmode == 4):\n",
    "            Manifold_Analysis(model,TestDataLoader,model_name,device,noise_val)\n",
    "        \n",
    "        if(pltmode == 5):\n",
    "            Visualize_Decoder_Weights(model,model_name,device,model_flag)\n",
    "            \n",
    "        if(pltmode == 6):\n",
    "            average_act(model,device,TestDataLoader,lossfn,test_length)\n",
    "            \n",
    "            \n",
    "                \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #initialising the lists\n",
    "        \n",
    "        train_losses   = []\n",
    "        test_losses    = []\n",
    "        \n",
    "        for epoch in range(1, N_epochs+1):\n",
    "            print(\"Epoch \",epoch,\" has just begun!\")\n",
    "            print('****************** ', epoch/N_epochs,\" % ******************\") #creates a status bar instead of using tqdm\n",
    "            \n",
    "            #train the model\n",
    "            loss = Train(model,device,TrainDataLoader,optimizer,lossfn,train_length,sparse = sparse,l1_reg = l1_reg,denoise = denoise,noise_val=noise_val,model_flag=model_flag)\n",
    "            train_losses.append(loss)\n",
    "            print('Train loss for Epoch ',epoch,': ',loss)\n",
    "    \n",
    "            #test the model\n",
    "            loss = Test(model,device,TestDataLoader,lossfn,test_length,sparse = sparse,l1_reg = l1_reg,denoise = denoise,noise_val=noise_val,model_flag=model_flag)\n",
    "            test_losses.append(loss)\n",
    "            print('Test loss for Epoch ',epoch,': ',loss)\n",
    "            \n",
    "            \n",
    "        #plotting the loss curves\n",
    "        \n",
    "        figure,axes = plt.subplots(2,1,constrained_layout = True,sharex = True)\n",
    "        \n",
    "        axes[0].plot(np.asfarray(train_losses),'o-',label = 'train losses')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].grid()\n",
    "        axes[0].legend()\n",
    "        \n",
    "        axes[1].plot(np.asfarray(test_losses),'o-',label= 'test losses')\n",
    "        axes[1].set_ylabel('Loss')\n",
    "        axes[1].set_xlabel('Iterations')\n",
    "        axes[1].grid()\n",
    "        axes[1].legend()\n",
    "        \n",
    "        figure.set_figwidth(8)\n",
    "        figure.set_figheight(10)\n",
    "        figure.suptitle(\"Training and testing plots for the Autoencoder\",x = 0.5,y=1.1)\n",
    "        figure.savefig(download_dir+'\\\\'+model_name+'_loss.png')\n",
    "        figure.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #showing final test loss\n",
    "        \n",
    "        final_loss = Test(model,device,TestDataLoader,lossfn,test_length,sparse = sparse,l1_reg = l1_reg,denoise = denoise,noise_val=noise_val,model_flag=model_flag)\n",
    "        \n",
    "        print('Final Reconstruction Loss = ',float(final_loss))\n",
    "        \n",
    "        # Save the model we just trained\n",
    "        torch.save(model.state_dict(), model_path+model_name)\n",
    "        print(model)\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Hyperparams:\n",
    "learning_rate = 1e-3\n",
    "batch_size    = 64\n",
    "N_epochs      = 10 \n",
    "\n",
    "\n",
    "#device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #checks for gpu else runs in cpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_Assignment():\n",
    "\n",
    "    answer = str(input('Do you want to check the results of question 1? (y/n)'))\n",
    "    \n",
    "    if(answer == 'y'):\n",
    "        \n",
    "        #Data Pre-processing\n",
    "        print('Pre-processing data......')\n",
    "        #getting the dataset ready\n",
    "        #Reusing code from assignment 1\n",
    "\n",
    "        #creating an mnist object\n",
    "\n",
    "        mnist_obj = MNIST1(mnist_path)\n",
    "        mnist_obj.gz = True #as I downloaded the .gz zip files\n",
    "        train_images,train_labels = mnist_obj.load_training() #loads the training dataset\n",
    "        test_images,test_labels   = mnist_obj.load_testing() #loads the testing dataset\n",
    "\n",
    "        print(\"Done extracting the data\")    \n",
    "\n",
    "        #modifications to training_data and testing_data\n",
    "\n",
    "        train_data = np.asarray(train_images)/255\n",
    "        test_data = np.asarray(test_images)/255\n",
    "        \n",
    "        answer = str(input('Do you want to take a look at the model test images?'))\n",
    "        \n",
    "        if(answer == 'y'):\n",
    "            Visualize_Image(test_images)\n",
    "            \n",
    "        \n",
    "        #running the PCA part of the assignment\n",
    "        print('Running the PCA with 30 principal components')\n",
    "        \n",
    "        PCA_data = np.concatenate((train_data,test_data))\n",
    "        \n",
    "        pca1 = PCA(n_components = 30) #as we take first 30 eigenvalues\n",
    "        pca1.fit(PCA_data)\n",
    "        train_pca = pca1.transform(PCA_data)\n",
    "        reconstructed_data = pca1.inverse_transform(train_pca)\n",
    "        PCA_error = mse(PCA_data,reconstructed_data)\n",
    "        print('Reconstruction error made by PCA: ',PCA_error)\n",
    "        \n",
    "        answer = str(input('Do you want to visualize the reconstructed images through PCA?'))\n",
    "        \n",
    "        if(answer == 'y'):\n",
    "            Visualize_Reconstr_PCA(reconstructed_data)\n",
    "            \n",
    "            \n",
    "        #running the AE part of this question\n",
    "        \n",
    "        print('Running the AE part....')\n",
    "        \n",
    "        model_name = 'Vanilla_AE.mdl'\n",
    "        \n",
    "        load_model = False\n",
    "        \n",
    "        model_flag = 0\n",
    "        \n",
    "        #Run_AE(model_name,load_model,model_flag)\n",
    "        \n",
    "        \n",
    "        answer = str(input('Do you want to visualize the reconstructed images through AE?'))\n",
    "        \n",
    "        if(answer == 'y'):\n",
    "            \n",
    "            model_name = 'Vanilla_AE.mdl'\n",
    "    \n",
    "            model_flag = 0\n",
    "            \n",
    "            load_model = True\n",
    "            \n",
    "            Run_AE(model_name,load_model,model_flag)\n",
    "            \n",
    "    answer = str(input('Do you want to check the results of question 2? (y/n)'))\n",
    "    \n",
    "    if(answer == 'y'):\n",
    "        \n",
    "        \n",
    "        x = [64,128,256] #size of the hidden layer\n",
    "        \n",
    "        for hidden_layer in x:\n",
    "\n",
    "            \n",
    "            model_name = 'AE_h_'+str(hidden_layer)+'.mdl'\n",
    "        \n",
    "            load_model = False\n",
    "        \n",
    "            model_flag = 1\n",
    "\n",
    "            #Run_AE(model_name,load_model,model_flag,hidden_layer=hidden_layer)\n",
    "            \n",
    "            answer = str(input('Do you want to visualize the reconstructed images through AE?'))\n",
    "        \n",
    "            if(answer == 'y'):\n",
    "            \n",
    "                load_model = True\n",
    "            \n",
    "                Run_AE(model_name,load_model,model_flag,hidden_layer=hidden_layer) \n",
    "                \n",
    "        \n",
    "        #testing the output of a non-digit image on the autoencoder\n",
    "        \n",
    "        answer = str(input('Do you want to check the output of the standard autoencoder when a non digit image is passed to it?'))\n",
    "        \n",
    "        if(answer == 'y'):\n",
    "            lena = im.open('lena.png').convert('L') #converts rgb image to gray scale\n",
    "            lena.save(download_dir+'\\\\'+'lena_greyscale.png') #saving the gray scale image\n",
    "            lena = np.asarray(lena)\n",
    "            x = img_as_ubyte(skimage.transform.resize(lena, (28,28))) #resizing to 28x28 pixels\n",
    "        \n",
    "            plt.imshow(x,cmap = plt.cm.gray, interpolation='nearest',clim=(0, 255))\n",
    "            plt.savefig(download_dir+'\\\\'+'lena_28x28.png')\n",
    "            plt.show()\n",
    "            \n",
    "            load_model = True\n",
    "            Run_AE(model_name,load_model,model_flag,hidden_layer=hidden_layer,pltmode = 1,img = x,name = 'lena')\n",
    "                \n",
    "    \n",
    "    answer = str(input('Do you want to check the results of question 3? (y/n)'))\n",
    "    \n",
    "    if(answer == 'y'):\n",
    "        \n",
    "        #train an overcomplete sparse Autoencoder\n",
    "        \n",
    "        x = 900 #hidden layer size \n",
    "            \n",
    "        reg_vals = [0.001,0.1,1] #try three different values of regularization\n",
    "                \n",
    "        for reg in reg_vals:\n",
    "            \n",
    "            model_name = 'AE_h_sparse'+str(reg)+str(x)+'.mdl'\n",
    "        \n",
    "            load_model = False\n",
    "        \n",
    "            model_flag = 1\n",
    "\n",
    "            #Run_AE(model_name,load_model,model_flag,hidden_layer=x,sparse = True,l1_reg = reg)\n",
    "            \n",
    "            answer = str(input('Do you want to visualize the reconstructed images through AE?'))\n",
    "        \n",
    "            if(answer == 'y'):\n",
    "            \n",
    "                load_model = True\n",
    "                Run_AE(model_name,load_model,model_flag,hidden_layer=x,sparse = True,l1_reg = reg) #produce reconstructed images\n",
    "                    \n",
    "                Run_AE(model_name,load_model,model_flag,hidden_layer=x,pltmode = 2,sparse = True,l1_reg = reg) #produce activation images\n",
    "                    \n",
    "                Run_AE(model_name,load_model,model_flag,hidden_layer=x,pltmode = 3,sparse = True,l1_reg = reg) #produce filter images\n",
    "                    \n",
    "        answer = str(input('Do you want to visualize the filters and the activations for the standard AE?'))\n",
    "            \n",
    "        if(answer == 'y'):\n",
    "                \n",
    "            model_name = 'AE_h_'+str(256)+'.mdl' #largest standard AE\n",
    "        \n",
    "            load_model = True\n",
    "        \n",
    "            model_flag = 1\n",
    "                \n",
    "            Run_AE(model_name,load_model,model_flag,hidden_layer=256,pltmode = 2) #produce activation images\n",
    "                    \n",
    "            Run_AE(model_name,load_model,model_flag,hidden_layer=256,pltmode = 3) #produce filter images\n",
    "                \n",
    "                    \n",
    "    answer = str(input('Do you want to check the results of question 4? (y/n)'))\n",
    "    \n",
    "    if(answer == 'y'): \n",
    "        \n",
    "        #train a denoising autoencoder with 256 hidden layer neurons\n",
    "        x = 256\n",
    "        \n",
    "        noise_vals = [0.1,0.3,0.7] #three different values of noise that we can use\n",
    "        \n",
    "        for noise_val in noise_vals:\n",
    "        \n",
    "            model_name = 'AE_h_denoise'+str(noise_val)+str(x)+'.mdl'\n",
    "        \n",
    "            load_model = False\n",
    "        \n",
    "            model_flag = 1\n",
    "\n",
    "            #Run_AE(model_name,load_model,model_flag,hidden_layer=x,denoise = True,noise_val = noise_val)\n",
    "            \n",
    "            answer = str(input('Do you want to visualize the reconstructed images through AE?'))\n",
    "        \n",
    "            if(answer == 'y'):\n",
    "            \n",
    "                load_model = True\n",
    "                Run_AE(model_name,load_model,model_flag,hidden_layer=x,denoise = True,noise_val = noise_val)\n",
    "                #Run_AE(model_name,load_model,model_flag,hidden_layer=x,pltmode = 3,denoise = True,noise_val = noise_val) #produce filter images\n",
    "        \n",
    "            \n",
    "        #testing noisy image on standard autoencoder\n",
    "        answer = str(input('Do you want to visualize the reconstructed images for a noisy input through AE?'))\n",
    "        if(answer == 'y'):\n",
    "            noisy_digit = im.open('Noisy_Image_8AE_h_denoise0.7256.mdl.png').convert('L') #converts rgb image to gray scale\n",
    "            noisy_digit = np.asarray(noisy_digit)\n",
    "            x_img = img_as_ubyte(skimage.transform.resize(noisy_digit, (28,28))) #resizing to 28x28 pixels\n",
    "        \n",
    "            plt.imshow(x_img,cmap = plt.cm.gray, interpolation='nearest',clim=(0, 255))\n",
    "            plt.savefig(download_dir+'\\\\'+'noisy_image_28x28.png')\n",
    "            plt.show()\n",
    "            \n",
    "            model_name = 'AE_h_'+str(x)+'.mdl'\n",
    "        \n",
    "            model_flag = 1\n",
    "            \n",
    "            load_model = True\n",
    "            Run_AE(model_name,load_model,model_flag,hidden_layer=x,pltmode = 1,img = x_img,name = 'noisy_image')\n",
    "                \n",
    "        \n",
    "    answer = str(input('Do you want to check the results of question 5? (y/n)'))\n",
    "    \n",
    "    if(answer == 'y'): \n",
    "        \n",
    "        \n",
    "        #training the AE for the manifold analysis\n",
    "        \n",
    "        model_name = 'AE_manifold.mdl'\n",
    "        \n",
    "        load_model = False\n",
    "        \n",
    "        model_flag = 2\n",
    "\n",
    "        #Run_AE(model_name,load_model,model_flag)\n",
    "        \n",
    "        answer = str(input('Do you want to visualize the reconstructed images?'))\n",
    "        if(answer == 'y'):\n",
    "            \n",
    "            load_model = True\n",
    "            \n",
    "            noise_vals = [0.1,0.3,0.7] #three different values of noise that we can use\n",
    "            \n",
    "            for noise_val in noise_vals:\n",
    "            \n",
    "                Run_AE(model_name,load_model,model_flag,pltmode = 4,noise_val = noise_val)\n",
    "            \n",
    "    \n",
    "    answer = str(input('Do you want to check the results of question 6? (y/n)'))\n",
    "    \n",
    "    if(answer == 'y'):\n",
    "        \n",
    "        answer = str(input('Do you want to check the results of question conv AE with unpooling? (y/n)'))\n",
    "    \n",
    "        if(answer == 'y'):\n",
    "            \n",
    "            #training the conv AE with unpooling\n",
    "            \n",
    "            model_name = 'conv_AE_unpool.mdl'\n",
    "        \n",
    "            load_model = False\n",
    "        \n",
    "            model_flag = 3\n",
    "            \n",
    "            Run_AE(model_name,load_model,model_flag)\n",
    "            \n",
    "        answer = str(input('Do you want to check the results of question conv AE with deconvolution? (y/n)'))\n",
    "    \n",
    "        if(answer == 'y'):\n",
    "            \n",
    "            #training the conv AE with deconvolution\n",
    "            \n",
    "            model_name = 'conv_AE_deconv.mdl'\n",
    "        \n",
    "            load_model = False\n",
    "        \n",
    "            model_flag = 4\n",
    "            \n",
    "            Run_AE(model_name,load_model,model_flag)\n",
    "            \n",
    "        answer = str(input('Do you want to check the results of question conv AE with unpooling and deconvolution? (y/n)'))\n",
    "    \n",
    "        if(answer == 'y'):\n",
    "            \n",
    "            #training the conv AE with deconvolution and unpooling\n",
    "            \n",
    "            model_name = 'conv_AE_unpool_deconv.mdl'\n",
    "        \n",
    "            load_model = False\n",
    "        \n",
    "            model_flag = 5\n",
    "            \n",
    "            Run_AE(model_name,load_model,model_flag)\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'AE_h_'+str(256)+'.mdl'\n",
    "        \n",
    "load_model = True\n",
    "        \n",
    "model_flag = 1\n",
    "\n",
    "Run_AE(model_name,load_model,model_flag,hidden_layer=256,pltmode = 6)\n",
    "\n",
    "x = 900 #hidden layer size \n",
    "            \n",
    "reg_vals = [0.001,0.1,1] #try three different values of regularization\n",
    "                \n",
    "for reg in reg_vals:\n",
    "            \n",
    "    model_name = 'AE_h_sparse'+str(reg)+str(x)+'.mdl'\n",
    "        \n",
    "    load_model = True\n",
    "        \n",
    "    model_flag = 1\n",
    "\n",
    "    Run_AE(model_name,load_model,model_flag,hidden_layer=x,sparse = True,l1_reg = reg,pltmode = 6)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
